{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Set the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the \"weed\" data in CSV format. The inputs are floating point values, the output is a class label encoded as an integer. The first entries in a row are the inputs, the final entry is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataTrain = tf.contrib.learn.datasets.base.load_csv_without_header(filename=\"../data/LSDA2017WeedCropTrain.csv\", \n",
    "                                                                   target_dtype=np.int, \n",
    "                                                                   features_dtype=np.float32, \n",
    "                                                                   target_column=-1)\n",
    "dataTest = tf.contrib.learn.datasets.base.load_csv_without_header(filename=\"../data/LSDA2017WeedCropTest.csv\", \n",
    "                                                                  target_dtype=np.int, \n",
    "                                                                  features_dtype=np.float32, \n",
    "                                                                  target_column=-1)\n",
    "\n",
    "# Input dimension\n",
    "inDim = dataTrain.data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `None` keyword in the `shape` definition corresponds to a variable-sized dimension. So the code works for any number of training or test data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, inDim], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Create variables for logistic regression\n",
    "A = tf.Variable(tf.random_normal(shape=[inDim,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Declare model operations\n",
    "model_output = tf.add(tf.matmul(x_data, A), b)\n",
    "\n",
    "# Declare loss function \n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n",
    "\n",
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.00001)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output of the model is the discriminant function, $\\delta$ on the slides. Applying a sigmoid maps $\\delta$ to the probability $P(y=1|x)$. Then we round the probability to the next integer, which corresponds to thresholding the probability at 0.5. This gives binary predictions. These are then compared to the desored targets. `tf.reduce_mean` computes the average, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Map model output to binary predictions\n",
    "prediction = tf.round(tf.sigmoid(model_output))\n",
    "predictions_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n",
    "accuracy = tf.reduce_mean(predictions_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Start session and run graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Start session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "loss_vec = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for i in range(10000):\n",
    "    sess.run(train_step, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    loss_vec.append(temp_loss)\n",
    "    temp_acc_train = sess.run(accuracy, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    train_acc.append(temp_acc_train)\n",
    "    temp_acc_test = sess.run(accuracy, feed_dict={x_data: dataTest.data, y_target: np.transpose([dataTest.target])})\n",
    "    test_acc.append(temp_acc_test)\n",
    "    if (i+1)%100==0:\n",
    "        print(str(i+1) + ': Loss = ' + str(temp_loss) + ', Training acc. = ' + str(temp_acc_train)  + \n",
    "              ', Test acc. = ' + str(temp_acc_test) )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Took me some time to correctly pass the labels in the binary case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(dataTest.target)\n",
    "print([dataTest.target])\n",
    "print(np.transpose([dataTest.target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(1)\n",
    "plt.plot(loss_vec, 'k-')\n",
    "plt.title('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "# Plot train and test accuracy\n",
    "plt.figure(2)\n",
    "plt.plot(train_acc, 'k-', label='Training')\n",
    "plt.plot(test_acc, 'r--', label='Test')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
