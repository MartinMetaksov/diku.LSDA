{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#       keep the memory allocated for the machine to 2GB!\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def zero_one_error_labels(y, y_hat):\n",
    "    return np.sum(y_hat == y)\n",
    "\n",
    "def mse (y,y_hat):\n",
    "    return np.mean(np.power(y-y_hat,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data ...\n",
      "Loaded training data: n=100000, d=15\n",
      "Loading testing data ...\n",
      "Loaded testing data: n=1000000, d=15\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Loading training data ...\")\n",
    "data_train = np.genfromtxt(\"../../data/neighbors/train.csv\", comments=\"#\", delimiter=\",\")\n",
    "Xtrain, ytrain = data_train[:,:-1], data_train[:,-1]\n",
    "print(\"Loaded training data: n=%i, d=%i\" % (Xtrain.shape[0], Xtrain.shape[1]))\n",
    "\n",
    "# testing phase (apply model to a big test set!)\n",
    "print(\"Loading testing data ...\")\n",
    "data_test = np.genfromtxt(\"../../data/neighbors/test.csv\", comments=\"#\", delimiter=\",\")\n",
    "Xtest, ytest = data_test[:,:-1], data_test[:,-1]\n",
    "print(\"Loaded testing data: n=%i, d=%i\" % (Xtest.shape[0], Xtest.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data ...\n",
      "Loaded validation data: n=100000, d=15\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading validation data ...\")\n",
    "data_validation = np.genfromtxt(\"../../data/neighbors/validation.csv\", comments=\"#\", delimiter=\",\")\n",
    "Xvd, yvd = data_validation[:,:-1], data_validation[:,-1]\n",
    "print(\"Loaded validation data: n=%i, d=%i\" % (Xvd.shape[0], Xvd.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model ...\n",
      "CPU times: user 368 ms, sys: 28 ms, total: 396 ms\n",
      "Wall time: 693 ms\n",
      "Model fitted!\n",
      "Applying model ...\n",
      "CPU times: user 5min 40s, sys: 836 ms, total: 5min 41s\n",
      "Wall time: 5min 41s\n",
      "Predictions computed for 1000000 patterns ...!\n",
      "Mean of predictions: 0.351215\n"
     ]
    }
   ],
   "source": [
    "# training phase\n",
    "print(\"Fitting model ...\")\n",
    "# nearest neighbor regression model (DO NOT CHANGE PARAMETERS!)\n",
    "model = KNeighborsRegressor(n_neighbors=10, algorithm=\"kd_tree\")\n",
    "%time model.fit(Xtrain, ytrain)\n",
    "print(\"Model fitted!\")\n",
    "\n",
    "print(\"Applying model ...\")\n",
    "% time preds = model.predict(Xtest)\n",
    "\n",
    "# output (here, 'preds' must be a list containing all predictions)\n",
    "print(\"Predictions computed for %i patterns ...!\" % len(preds))\n",
    "print(\"Mean of predictions: %f\" % np.mean(np.array(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test: 0.225451\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean Squared Error on test: %f\" % mse(ytest,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data: n=100000, d=5\n",
      "Fitting model ...\n",
      "CPU times: user 236 ms, sys: 0 ns, total: 236 ms\n",
      "Wall time: 237 ms\n",
      "Model fitted!\n",
      "Applying model ...\n",
      "CPU times: user 52.8 s, sys: 612 ms, total: 53.4 s\n",
      "Wall time: 53.5 s\n",
      "Predictions computed for 1000000 patterns ...!\n",
      "Mean of predictions: 0.351215\n"
     ]
    }
   ],
   "source": [
    "# select only first 5 columns from the train data\n",
    "Xtrain_5feat = data_train[:,0:5]\n",
    "\n",
    "print(\"Loaded training data: n=%i, d=%i\" % (Xtrain_5feat.shape[0], Xtrain_5feat.shape[1]))\n",
    "\n",
    "# training phase\n",
    "print(\"Fitting model ...\")\n",
    "%time model.fit(Xtrain_5feat, ytrain)\n",
    "print(\"Model fitted!\")\n",
    "\n",
    "# testing phase (apply model to a big test set!)\n",
    "Xtest_5feat = data_test[:,0:5]\n",
    "\n",
    "print(\"Applying model ...\")\n",
    "%time preds_5feat = model.predict(Xtest_5feat)\n",
    "\n",
    "# output (here, 'preds' must be a list containing all predictions)\n",
    "print(\"Predictions computed for %i patterns ...!\" % len(preds))\n",
    "print(\"Mean of predictions: %f\" % np.mean(np.array(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test using only 5 features: 0.246566\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error on test using only 5 features: %f\" % mse(ytest,preds_5feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for columns [0] ...\n",
      "CPU times: user 276 ms, sys: 0 ns, total: 276 ms\n",
      "Wall time: 273 ms\n",
      "Fitting for columns [1] ...\n",
      "CPU times: user 184 ms, sys: 0 ns, total: 184 ms\n",
      "Wall time: 186 ms\n",
      "Fitting for columns [2] ...\n",
      "CPU times: user 208 ms, sys: 0 ns, total: 208 ms\n",
      "Wall time: 209 ms\n",
      "Fitting for columns [3] ...\n",
      "CPU times: user 272 ms, sys: 0 ns, total: 272 ms\n",
      "Wall time: 270 ms\n",
      "Fitting for columns [4] ...\n",
      "CPU times: user 228 ms, sys: 0 ns, total: 228 ms\n",
      "Wall time: 230 ms\n",
      "Fitting for columns [5] ...\n",
      "CPU times: user 208 ms, sys: 0 ns, total: 208 ms\n",
      "Wall time: 210 ms\n",
      "Fitting for columns [6] ...\n",
      "CPU times: user 228 ms, sys: 0 ns, total: 228 ms\n",
      "Wall time: 229 ms\n",
      "Fitting for columns [7] ...\n",
      "CPU times: user 244 ms, sys: 0 ns, total: 244 ms\n",
      "Wall time: 241 ms\n",
      "Fitting for columns [8] ...\n",
      "CPU times: user 216 ms, sys: 0 ns, total: 216 ms\n",
      "Wall time: 217 ms\n",
      "Fitting for columns [9] ...\n",
      "CPU times: user 208 ms, sys: 0 ns, total: 208 ms\n",
      "Wall time: 211 ms\n",
      "Fitting for columns [10] ...\n",
      "CPU times: user 248 ms, sys: 0 ns, total: 248 ms\n",
      "Wall time: 258 ms\n",
      "Fitting for columns [11] ...\n",
      "CPU times: user 228 ms, sys: 0 ns, total: 228 ms\n",
      "Wall time: 228 ms\n",
      "Fitting for columns [12] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 200 ms\n",
      "Fitting for columns [13] ...\n",
      "CPU times: user 240 ms, sys: 0 ns, total: 240 ms\n",
      "Wall time: 242 ms\n",
      "Fitting for columns [14] ...\n",
      "CPU times: user 212 ms, sys: 0 ns, total: 212 ms\n",
      "Wall time: 212 ms\n",
      "Fitting for columns [9, 0] ...\n",
      "CPU times: user 96 ms, sys: 0 ns, total: 96 ms\n",
      "Wall time: 95.4 ms\n",
      "Fitting for columns [9, 1] ...\n",
      "CPU times: user 84 ms, sys: 0 ns, total: 84 ms\n",
      "Wall time: 83.4 ms\n",
      "Fitting for columns [9, 2] ...\n",
      "CPU times: user 104 ms, sys: 0 ns, total: 104 ms\n",
      "Wall time: 104 ms\n",
      "Fitting for columns [9, 3] ...\n",
      "CPU times: user 88 ms, sys: 0 ns, total: 88 ms\n",
      "Wall time: 88.5 ms\n",
      "Fitting for columns [9, 4] ...\n",
      "CPU times: user 100 ms, sys: 0 ns, total: 100 ms\n",
      "Wall time: 101 ms\n",
      "Fitting for columns [9, 5] ...\n",
      "CPU times: user 112 ms, sys: 0 ns, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "Fitting for columns [9, 6] ...\n",
      "CPU times: user 84 ms, sys: 0 ns, total: 84 ms\n",
      "Wall time: 83 ms\n",
      "Fitting for columns [9, 7] ...\n",
      "CPU times: user 92 ms, sys: 0 ns, total: 92 ms\n",
      "Wall time: 92 ms\n",
      "Fitting for columns [9, 8] ...\n",
      "CPU times: user 140 ms, sys: 0 ns, total: 140 ms\n",
      "Wall time: 137 ms\n",
      "Fitting for columns [9, 10] ...\n",
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 137 ms\n",
      "Fitting for columns [9, 11] ...\n",
      "CPU times: user 68 ms, sys: 0 ns, total: 68 ms\n",
      "Wall time: 67.7 ms\n",
      "Fitting for columns [9, 12] ...\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 121 ms\n",
      "Fitting for columns [9, 13] ...\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 113 ms\n",
      "Fitting for columns [9, 14] ...\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 117 ms\n",
      "Fitting for columns [9, 0, 1] ...\n",
      "CPU times: user 88 ms, sys: 0 ns, total: 88 ms\n",
      "Wall time: 87.2 ms\n",
      "Fitting for columns [9, 0, 2] ...\n",
      "CPU times: user 88 ms, sys: 0 ns, total: 88 ms\n",
      "Wall time: 87.8 ms\n",
      "Fitting for columns [9, 0, 3] ...\n",
      "CPU times: user 112 ms, sys: 0 ns, total: 112 ms\n",
      "Wall time: 113 ms\n",
      "Fitting for columns [9, 0, 4] ...\n",
      "CPU times: user 172 ms, sys: 0 ns, total: 172 ms\n",
      "Wall time: 173 ms\n",
      "Fitting for columns [9, 0, 5] ...\n",
      "CPU times: user 124 ms, sys: 4 ms, total: 128 ms\n",
      "Wall time: 125 ms\n",
      "Fitting for columns [9, 0, 6] ...\n",
      "CPU times: user 140 ms, sys: 0 ns, total: 140 ms\n",
      "Wall time: 140 ms\n",
      "Fitting for columns [9, 0, 7] ...\n",
      "CPU times: user 152 ms, sys: 0 ns, total: 152 ms\n",
      "Wall time: 150 ms\n",
      "Fitting for columns [9, 0, 8] ...\n",
      "CPU times: user 184 ms, sys: 0 ns, total: 184 ms\n",
      "Wall time: 184 ms\n",
      "Fitting for columns [9, 0, 10] ...\n",
      "CPU times: user 100 ms, sys: 0 ns, total: 100 ms\n",
      "Wall time: 99.6 ms\n",
      "Fitting for columns [9, 0, 11] ...\n",
      "CPU times: user 124 ms, sys: 0 ns, total: 124 ms\n",
      "Wall time: 122 ms\n",
      "Fitting for columns [9, 0, 12] ...\n",
      "CPU times: user 160 ms, sys: 0 ns, total: 160 ms\n",
      "Wall time: 156 ms\n",
      "Fitting for columns [9, 0, 13] ...\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 115 ms\n",
      "Fitting for columns [9, 0, 14] ...\n",
      "CPU times: user 152 ms, sys: 0 ns, total: 152 ms\n",
      "Wall time: 154 ms\n",
      "Fitting for columns [9, 0, 2, 1] ...\n",
      "CPU times: user 108 ms, sys: 0 ns, total: 108 ms\n",
      "Wall time: 109 ms\n",
      "Fitting for columns [9, 0, 2, 3] ...\n",
      "CPU times: user 100 ms, sys: 0 ns, total: 100 ms\n",
      "Wall time: 99.8 ms\n",
      "Fitting for columns [9, 0, 2, 4] ...\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 114 ms\n",
      "Fitting for columns [9, 0, 2, 5] ...\n",
      "CPU times: user 176 ms, sys: 0 ns, total: 176 ms\n",
      "Wall time: 176 ms\n",
      "Fitting for columns [9, 0, 2, 6] ...\n",
      "CPU times: user 128 ms, sys: 0 ns, total: 128 ms\n",
      "Wall time: 128 ms\n",
      "Fitting for columns [9, 0, 2, 7] ...\n",
      "CPU times: user 208 ms, sys: 0 ns, total: 208 ms\n",
      "Wall time: 211 ms\n",
      "Fitting for columns [9, 0, 2, 8] ...\n",
      "CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n",
      "Wall time: 147 ms\n",
      "Fitting for columns [9, 0, 2, 10] ...\n",
      "CPU times: user 188 ms, sys: 0 ns, total: 188 ms\n",
      "Wall time: 186 ms\n",
      "Fitting for columns [9, 0, 2, 11] ...\n",
      "CPU times: user 108 ms, sys: 0 ns, total: 108 ms\n",
      "Wall time: 108 ms\n",
      "Fitting for columns [9, 0, 2, 12] ...\n",
      "CPU times: user 172 ms, sys: 0 ns, total: 172 ms\n",
      "Wall time: 170 ms\n",
      "Fitting for columns [9, 0, 2, 13] ...\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 120 ms\n",
      "Fitting for columns [9, 0, 2, 14] ...\n",
      "CPU times: user 128 ms, sys: 0 ns, total: 128 ms\n",
      "Wall time: 126 ms\n",
      "Fitting for columns [9, 0, 2, 6, 1] ...\n",
      "CPU times: user 180 ms, sys: 4 ms, total: 184 ms\n",
      "Wall time: 181 ms\n",
      "Fitting for columns [9, 0, 2, 6, 3] ...\n",
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 138 ms\n",
      "Fitting for columns [9, 0, 2, 6, 4] ...\n",
      "CPU times: user 188 ms, sys: 0 ns, total: 188 ms\n",
      "Wall time: 188 ms\n",
      "Fitting for columns [9, 0, 2, 6, 5] ...\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 120 ms\n",
      "Fitting for columns [9, 0, 2, 6, 7] ...\n",
      "CPU times: user 168 ms, sys: 0 ns, total: 168 ms\n",
      "Wall time: 172 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8] ...\n",
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 138 ms\n",
      "Fitting for columns [9, 0, 2, 6, 10] ...\n",
      "CPU times: user 236 ms, sys: 20 ms, total: 256 ms\n",
      "Wall time: 254 ms\n",
      "Fitting for columns [9, 0, 2, 6, 11] ...\n",
      "CPU times: user 124 ms, sys: 0 ns, total: 124 ms\n",
      "Wall time: 126 ms\n",
      "Fitting for columns [9, 0, 2, 6, 12] ...\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 115 ms\n",
      "Fitting for columns [9, 0, 2, 6, 13] ...\n",
      "CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n",
      "Wall time: 144 ms\n",
      "Fitting for columns [9, 0, 2, 6, 14] ...\n",
      "CPU times: user 220 ms, sys: 0 ns, total: 220 ms\n",
      "Wall time: 219 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 1] ...\n",
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 136 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 3] ...\n",
      "CPU times: user 176 ms, sys: 0 ns, total: 176 ms\n",
      "Wall time: 179 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 4] ...\n",
      "CPU times: user 164 ms, sys: 0 ns, total: 164 ms\n",
      "Wall time: 163 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 5] ...\n",
      "CPU times: user 140 ms, sys: 0 ns, total: 140 ms\n",
      "Wall time: 140 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 7] ...\n",
      "CPU times: user 148 ms, sys: 0 ns, total: 148 ms\n",
      "Wall time: 147 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 10] ...\n",
      "CPU times: user 156 ms, sys: 0 ns, total: 156 ms\n",
      "Wall time: 153 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 11] ...\n",
      "CPU times: user 148 ms, sys: 0 ns, total: 148 ms\n",
      "Wall time: 148 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12] ...\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 122 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 13] ...\n",
      "CPU times: user 228 ms, sys: 0 ns, total: 228 ms\n",
      "Wall time: 227 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 14] ...\n",
      "CPU times: user 160 ms, sys: 0 ns, total: 160 ms\n",
      "Wall time: 157 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 1] ...\n",
      "CPU times: user 164 ms, sys: 0 ns, total: 164 ms\n",
      "Wall time: 165 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 3] ...\n",
      "CPU times: user 184 ms, sys: 4 ms, total: 188 ms\n",
      "Wall time: 185 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 4] ...\n",
      "CPU times: user 188 ms, sys: 0 ns, total: 188 ms\n",
      "Wall time: 190 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 5] ...\n",
      "CPU times: user 164 ms, sys: 0 ns, total: 164 ms\n",
      "Wall time: 164 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 7] ...\n",
      "CPU times: user 164 ms, sys: 0 ns, total: 164 ms\n",
      "Wall time: 165 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 10] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 198 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11] ...\n",
      "CPU times: user 180 ms, sys: 0 ns, total: 180 ms\n",
      "Wall time: 177 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 13] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 199 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 14] ...\n",
      "CPU times: user 184 ms, sys: 0 ns, total: 184 ms\n",
      "Wall time: 183 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1] ...\n",
      "CPU times: user 188 ms, sys: 0 ns, total: 188 ms\n",
      "Wall time: 189 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 3] ...\n",
      "CPU times: user 188 ms, sys: 0 ns, total: 188 ms\n",
      "Wall time: 189 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 4] ...\n",
      "CPU times: user 208 ms, sys: 4 ms, total: 212 ms\n",
      "Wall time: 213 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 5] ...\n",
      "CPU times: user 184 ms, sys: 0 ns, total: 184 ms\n",
      "Wall time: 182 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 7] ...\n",
      "CPU times: user 268 ms, sys: 0 ns, total: 268 ms\n",
      "Wall time: 267 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 10] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 203 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 13] ...\n",
      "CPU times: user 224 ms, sys: 0 ns, total: 224 ms\n",
      "Wall time: 222 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 14] ...\n",
      "CPU times: user 220 ms, sys: 0 ns, total: 220 ms\n",
      "Wall time: 220 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 3] ...\n",
      "CPU times: user 220 ms, sys: 0 ns, total: 220 ms\n",
      "Wall time: 222 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 4] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 202 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 5] ...\n",
      "CPU times: user 212 ms, sys: 0 ns, total: 212 ms\n",
      "Wall time: 210 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7] ...\n",
      "CPU times: user 196 ms, sys: 0 ns, total: 196 ms\n",
      "Wall time: 197 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 10] ...\n",
      "CPU times: user 292 ms, sys: 4 ms, total: 296 ms\n",
      "Wall time: 299 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 13] ...\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 201 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 14] ...\n",
      "CPU times: user 192 ms, sys: 0 ns, total: 192 ms\n",
      "Wall time: 194 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 3] ...\n",
      "CPU times: user 232 ms, sys: 0 ns, total: 232 ms\n",
      "Wall time: 231 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4] ...\n",
      "CPU times: user 244 ms, sys: 0 ns, total: 244 ms\n",
      "Wall time: 244 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 5] ...\n",
      "CPU times: user 208 ms, sys: 4 ms, total: 212 ms\n",
      "Wall time: 212 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 10] ...\n",
      "CPU times: user 220 ms, sys: 0 ns, total: 220 ms\n",
      "Wall time: 218 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 13] ...\n",
      "CPU times: user 280 ms, sys: 0 ns, total: 280 ms\n",
      "Wall time: 280 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 14] ...\n",
      "CPU times: user 264 ms, sys: 0 ns, total: 264 ms\n",
      "Wall time: 265 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 3] ...\n",
      "CPU times: user 252 ms, sys: 0 ns, total: 252 ms\n",
      "Wall time: 252 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 5] ...\n",
      "CPU times: user 252 ms, sys: 0 ns, total: 252 ms\n",
      "Wall time: 254 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 10] ...\n",
      "CPU times: user 240 ms, sys: 0 ns, total: 240 ms\n",
      "Wall time: 241 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13] ...\n",
      "CPU times: user 264 ms, sys: 0 ns, total: 264 ms\n",
      "Wall time: 263 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 14] ...\n",
      "CPU times: user 360 ms, sys: 0 ns, total: 360 ms\n",
      "Wall time: 360 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3] ...\n",
      "CPU times: user 304 ms, sys: 0 ns, total: 304 ms\n",
      "Wall time: 301 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 5] ...\n",
      "CPU times: user 304 ms, sys: 4 ms, total: 308 ms\n",
      "Wall time: 309 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 10] ...\n",
      "CPU times: user 260 ms, sys: 0 ns, total: 260 ms\n",
      "Wall time: 259 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 14] ...\n",
      "CPU times: user 280 ms, sys: 0 ns, total: 280 ms\n",
      "Wall time: 279 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5] ...\n",
      "CPU times: user 328 ms, sys: 0 ns, total: 328 ms\n",
      "Wall time: 327 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 10] ...\n",
      "CPU times: user 296 ms, sys: 0 ns, total: 296 ms\n",
      "Wall time: 298 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 14] ...\n",
      "CPU times: user 300 ms, sys: 0 ns, total: 300 ms\n",
      "Wall time: 299 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5, 10] ...\n",
      "CPU times: user 340 ms, sys: 0 ns, total: 340 ms\n",
      "Wall time: 338 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5, 14] ...\n",
      "CPU times: user 312 ms, sys: 0 ns, total: 312 ms\n",
      "Wall time: 312 ms\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5, 14, 10] ...\n",
      "CPU times: user 412 ms, sys: 0 ns, total: 412 ms\n",
      "Wall time: 414 ms\n"
     ]
    }
   ],
   "source": [
    "# Select the best features by iteratively selecting good features\n",
    "X_tr = data_train[:,:-1]\n",
    "X_vd = data_validation[:,:-1]\n",
    "n_feat = 15\n",
    "n = X_tr.shape[1]\n",
    "results = np.zeros([n_feat,n])\n",
    "fs = []\n",
    "for fi in range(n_feat):\n",
    "    n_features = fi+1\n",
    "    for i in range(n):\n",
    "        if i in fs :\n",
    "            continue\n",
    "        # select features , train and predict, keep training error\n",
    "        f = fs + [i]\n",
    "        Xtr = X_tr[:,f]\n",
    "        Xvd = X_vd[:,f]\n",
    "        print(\"Fitting for columns %s ...\" % str(f))\n",
    "        %time model.fit(Xtr, ytrain)\n",
    "        pred = model.predict(Xvd)\n",
    "        results[n_features-1,i] = mse(yvd, pred)\n",
    "    best = np.argsort(results,1)[n_features-1][fi]\n",
    "    fs.append(best);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for columns [9, 0, 2, 6, 8] ...\n",
      "CPU times: user 4.03 s, sys: 4 ms, total: 4.03 s\n",
      "Wall time: 4.04 s\n",
      "Best MSE is 0.187799 ...\n"
     ]
    }
   ],
   "source": [
    "# test with the 5 best features\n",
    "Xtr = X_tr[:,fs[0:5]]\n",
    "Xvd = X_vd[:,fs[0:5]]\n",
    "print(\"Fitting for columns %s ...\" % str(fs[0:5]))\n",
    "model.fit(Xtr, ytrain)\n",
    "%time pred = model.predict(Xvd)\n",
    "print(\"Best MSE is %f ...\" % mse(yvd, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  8, 13, 14, 12,  7,  4,  3, 11,  6,  2,  1,  5, 10,  0],\n",
       "       [ 9,  0,  5,  1,  6, 10, 11,  3,  2,  7,  8, 12,  4, 13, 14],\n",
       "       [ 0,  9,  2,  1,  7, 12,  6, 11,  3,  8, 13,  4,  5, 10, 14],\n",
       "       [ 0,  2,  9,  6, 11,  1,  8,  3, 13, 12,  7,  4,  5, 14, 10],\n",
       "       [ 0,  2,  6,  9,  8, 13,  3,  7, 12,  1, 11,  4,  5, 14, 10],\n",
       "       [ 0,  2,  6,  8,  9, 12,  4,  7, 11,  1,  3, 13,  5, 14, 10],\n",
       "       [ 0,  2,  6,  8,  9, 12, 11,  1,  4,  7,  3, 13, 14,  5, 10],\n",
       "       [ 0,  2,  6,  8,  9, 11, 12,  1,  7,  4,  3, 13,  5, 14, 10],\n",
       "       [ 0,  1,  2,  6,  8,  9, 11, 12,  7,  4, 13,  3,  5, 14, 10],\n",
       "       [ 0,  1,  2,  6,  7,  8,  9, 11, 12,  4, 13,  3,  5, 14, 10],\n",
       "       [ 0,  1,  2,  4,  6,  7,  8,  9, 11, 12, 13,  3,  5, 14, 10],\n",
       "       [ 0,  1,  2,  4,  6,  7,  8,  9, 11, 12, 13,  3,  5, 14, 10],\n",
       "       [ 0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 12, 13,  5, 14, 10],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 10],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(results,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for columns [9] ...\n",
      "Got MSE 0.287118 ...\n",
      "Fitting for columns [9, 0] ...\n",
      "Got MSE 0.256977 ...\n",
      "Fitting for columns [9, 0, 2] ...\n",
      "Got MSE 0.213786 ...\n",
      "Fitting for columns [9, 0, 2, 6] ...\n",
      "Got MSE 0.195752 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8] ...\n",
      "Got MSE 0.187799 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12] ...\n",
      "Got MSE 0.185616 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11] ...\n",
      "Got MSE 0.184218 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1] ...\n",
      "Got MSE 0.183136 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7] ...\n",
      "Got MSE 0.183133 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4] ...\n",
      "Got MSE 0.183057 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13] ...\n",
      "Got MSE 0.182403 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3] ...\n",
      "Got MSE 0.181423 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5] ...\n",
      "Got MSE 0.183237 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5, 14] ...\n",
      "Got MSE 0.185271 ...\n",
      "Fitting for columns [9, 0, 2, 6, 8, 12, 11, 1, 7, 4, 13, 3, 5, 14, 10] ...\n",
      "Got MSE 0.190905 ...\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "X = range(1,16)\n",
    "for i in X:\n",
    "    Xtr = X_tr[:,fs[0:i]]\n",
    "    Xvd = X_vd[:,fs[0:i]]\n",
    "    print(\"Fitting for columns %s ...\" % str(fs[0:i]))\n",
    "    model.fit(Xtr, ytrain)\n",
    "    p = model.predict(Xvd)\n",
    "    pred[i]=mse(yvd, p)\n",
    "    print(\"Got MSE %f ...\" % pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabe0965790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X,pred.values())\n",
    "plt.scatter(X,pred.values())\n",
    "plt.xticks(X)\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.ylabel(\"MSE accuracy\")\n",
    "plt.title(\"Nearest Neighbor forward feature selection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2871177420905488,\n",
       " 0.25697665982996526,\n",
       " 0.21378624116864187,\n",
       " 0.19575152286306835,\n",
       " 0.18779908194319717,\n",
       " 0.18561600593988395,\n",
       " 0.18421756379572052,\n",
       " 0.18313586560856884,\n",
       " 0.18313260966194408,\n",
       " 0.18305676862145451,\n",
       " 0.18240330246922701,\n",
       " 0.1814225093232554,\n",
       " 0.18323725235880048,\n",
       " 0.18527050375389001,\n",
       " 0.19090516015169812]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
