{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flags\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('summary_dir', '/tmp/logLog', 'directory to put the summary data')\n",
    "flags.DEFINE_string('data_dir', '../data', 'directory with data')\n",
    "flags.DEFINE_integer('maxIter', 10000, 'number of iterations')\n",
    "flags.DEFINE_float('l_rate',0.01,'learning rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "dataTrain = tf.contrib.learn.datasets.base.load_csv_without_header(filename=FLAGS.data_dir + '/LSDA2017WeedCropTrain.csv', target_dtype=np.int, features_dtype=np.float32, target_column=-1)\n",
    "dataTest = tf.contrib.learn.datasets.base.load_csv_without_header(filename=FLAGS.data_dir + '/LSDA2017WeedCropTest.csv', target_dtype=np.int, features_dtype=np.float32, target_column=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "inDim = dataTrain.data.shape[1]\n",
    "# Create graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, inDim], dtype=tf.float32, name='input')\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32, name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorBoard will collapse the following nodes \n",
    "with tf.name_scope('model') as scope:\n",
    "    # Create variables for logistic regression\n",
    "    A = tf.Variable(tf.random_normal(shape=[inDim,1]))\n",
    "    b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "    # Declare model operations\n",
    "    model_output = tf.add(tf.matmul(x_data, A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare loss function \n",
    "with tf.name_scope('loss') as scope:\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n",
    "    tf.summary.scalar('cross-entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(FLAGS.l_rate)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map model output to binary predictions\n",
    "with tf.name_scope('binary_prediction') as scope:\n",
    "    prediction = tf.round(tf.sigmoid(model_output))\n",
    "with tf.name_scope('0-1-loss') as scope:\n",
    "    predictions_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n",
    "    accuracy = tf.reduce_mean(predictions_correct)\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logging\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(FLAGS.summary_dir + '/train',sess.graph)\n",
    "test_writer = tf.summary.FileWriter(FLAGS.summary_dir + '/test',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for i in range(FLAGS.maxIter):\n",
    "    sess.run(train_step, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    summary = sess.run(merged, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])})\n",
    "    train_writer.add_summary(summary, i)\n",
    "    summary = sess.run(merged, feed_dict={x_data: dataTest.data, y_target: np.transpose([dataTest.target])})\n",
    "    test_writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"final training accuracy:\", sess.run(accuracy, feed_dict={x_data: dataTrain.data, y_target: np.transpose([dataTrain.target])}), \"final test accuracy: \", sess.run(accuracy, feed_dict={x_data: dataTest.data, y_target: np.transpose([dataTest.target])}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
