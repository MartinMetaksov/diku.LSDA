{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing line 0 ...\n",
      "Processing line 1000000 ...\n",
      "Processing line 2000000 ...\n",
      "Processing line 3000000 ...\n",
      "Processing line 4000000 ...\n",
      "Processing line 5000000 ...\n",
      "Processing line 6000000 ...\n",
      "Processing line 7000000 ...\n",
      "Processing line 8000000 ...\n",
      "Processing line 9000000 ...\n",
      "Processing line 10000000 ...\n",
      "Processing line 11000000 ...\n",
      "Processing line 12000000 ...\n",
      "Processing line 13000000 ...\n",
      "Processing line 14000000 ...\n",
      "Processing line 15000000 ...\n",
      "Processing line 16000000 ...\n",
      "Processing line 17000000 ...\n",
      "Processing line 18000000 ...\n",
      "Processing line 19000000 ...\n",
      "Processing line 20000000 ...\n",
      "Processing line 21000000 ...\n",
      "Processing line 22000000 ...\n",
      "Processing line 23000000 ...\n",
      "Processing line 24000000 ...\n",
      "Processing line 25000000 ...\n"
     ]
    }
   ],
   "source": [
    "# Goal: Process landsat_train.csv and extract\n",
    "# a subset of 100,000 training instances\n",
    "#\n",
    "# Output: New files landsat_train_subset.csv and landsat_train_remaining.csv\n",
    "\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "# Open files\n",
    "landsat_train = open(\"../../data/landsat_train.csv\", 'r')\n",
    "landsat_train_subset = open(\"landsat_train_subset.csv\", 'w')\n",
    "landsat_train_remaining = open(\"landsat_train_remaining.csv\", 'w')\n",
    "\n",
    "# Generate sorted subset of indices. Since this\n",
    "# list is relatively small, we can simply genearte\n",
    "# and keep it in main memory\n",
    "subset = sorted(numpy.random.choice(25667779, 100000, replace=False))\n",
    "\n",
    "# Process training file line-by-line\n",
    "counter = 0\n",
    "counter_subset = 0\n",
    "\n",
    "for line in landsat_train:\n",
    "\n",
    "    if counter % 1000000 == 0:\n",
    "        print(\"Processing line %i ...\" % counter)\n",
    "\n",
    "    if counter_subset < len(subset) and counter == subset[counter_subset]:\n",
    "        # Append to subset file\n",
    "        landsat_train_subset.write(line)\n",
    "        counter_subset += 1\n",
    "    else:\n",
    "        # Append to remaining file\n",
    "        landsat_train_remaining.write(line)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "# Close files\n",
    "landsat_train.close()\n",
    "landsat_train_subset.close()\n",
    "landsat_train_remaining.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data ...\n",
      "Loaded training data: n=100000, d=9\n",
      "Fitting model ...\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load data\n",
    "print(\"Loading training data ...\")\n",
    "data_train = numpy.genfromtxt(\"landsat_train_subset.csv\", delimiter=\",\")\n",
    "Xtrain, ytrain = data_train[:,1:], data_train[:,0]\n",
    "print(\"Loaded training data: n=%i, d=%i\" % (Xtrain.shape[0], Xtrain.shape[1]))\n",
    "\n",
    "# training phase\n",
    "print(\"Fitting model ...\")\n",
    "model = RandomForestClassifier(n_estimators=10, \n",
    "                               criterion='gini',\n",
    "                               max_depth=None, \n",
    "                               min_samples_split=2, \n",
    "                               max_features=None)\n",
    "model.fit(Xtrain, ytrain)\n",
    "print(\"Model fitted!\")\n",
    "\n",
    "# save model\n",
    "pickle.dump(model, open(\"model.save\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
